{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16191f5-62cb-4833-bc8c-70ab68f18e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from my_extension import my_extension as myext\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5bbde8-8fd0-4d55-bd32-00275855a30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(myext.linear_cpp_precompiled.__file__)  # pre-compiled with `python setup.py install`\n",
    "# print(myext.linear_cpp_precompiled.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796b5093-6bfc-4ca7-a064-f5a97aa4eda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/techix/.cache/torch_extensions/py310_cu117/linear_cpp/linear_cpp.so\n",
      "<built-in method forward of PyCapsule object at 0x7f4dd00d9290>\n"
     ]
    }
   ],
   "source": [
    "# print(myext.backend.__file__)\n",
    "print(myext._C.__file__)  # JIT using `load()` in csrc submodule\n",
    "print(myext._C.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3d7bcf-344a-4028-bcc2-88c8be2c5e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/techix/.cache/torch_extensions/py310_cu117/linear_cuda/linear_cuda.so\n",
      "<built-in method forward of PyCapsule object at 0x7f4dd00d93e0>\n"
     ]
    }
   ],
   "source": [
    "print(myext._CU.__file__)  # JIT using `load()` in csrc submodule\n",
    "print(myext._CU.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9dc761-a813-4fd0-b9e4-781ee60eb04d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = 'cuda:0'\n",
    "n_h = 3\n",
    "n_in = 2\n",
    "n_batch = 1\n",
    "\n",
    "# X = torch.ones(n_batch, n_in, device=device)\n",
    "X = torch.randn(n_batch, n_in, device=device)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f949f1-a69b-4bd6-97cc-bd10c4398f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6678,  0.4115],\n",
      "        [-0.0438, -0.2404],\n",
      "        [-0.2341, -0.1721]], device='cuda:0', requires_grad=True) Parameter containing:\n",
      "tensor([-0.6796,  0.3866,  0.5163], device='cuda:0', requires_grad=True)\n",
      "<AddmmBackward0 object at 0x7f4dd00d9930>\n"
     ]
    }
   ],
   "source": [
    "## Setup models\n",
    "lin_gt = torch.nn.Linear(n_in, n_h, device=device)\n",
    "z1_gt = lin_gt(X)\n",
    "# print(z1_py.shape, '\\n', z1_py)\n",
    "\n",
    "W1, b1 = lin_gt.parameters()\n",
    "print(W1, b1)\n",
    "print(z1_gt.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4fad4d-d3cf-46ba-bc14-bf3fc4bfa9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "## Check LinearPytorch forward method\n",
    "W1_py, b1_py = W1.detach().clone(), b1.detach().clone()\n",
    "W1_py.requires_grad = True\n",
    "b1_py.requires_grad = True\n",
    "lin_py = myext.LinearPytorch()\n",
    "z1_py = lin_py.apply(X, W1_py, b1_py)\n",
    "print(z1_py.shape)\n",
    "print(z1_py.shape)\n",
    "torch.testing.assert_close(z1_gt, z1_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e41871-0b2f-47b5-966c-a0f8e8477c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9247, 0.4253],\n",
      "        [0.9247, 0.4253],\n",
      "        [0.9247, 0.4253]], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0')\n",
      "tensor([[0.9247, 0.4253],\n",
      "        [0.9247, 0.4253],\n",
      "        [0.9247, 0.4253]], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Check LinearPytorch backward method\n",
    "abs(z1_gt.sum()).backward(retain_graph=True)\n",
    "print(W1.grad, b1.grad)\n",
    "\n",
    "abs(z1_py.sum()).backward(retain_graph=True)\n",
    "print(W1_py.grad, b1_py.grad)\n",
    "\n",
    "torch.testing.assert_close(W1.grad, W1_py.grad)\n",
    "torch.testing.assert_close(b1.grad, b1_py.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b153e6-0e00-4252-8156-452379b520fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "## Check LinearCPP forward method\n",
    "W1_cpp, b1_cpp = W1.detach().clone(), b1.detach().clone()\n",
    "W1_cpp.requires_grad = True\n",
    "b1_cpp.requires_grad = True\n",
    "lin_cpp = myext.LinearCPP()\n",
    "z1_cpp = lin_cpp.apply(X, W1_cpp, b1_cpp)\n",
    "print(z1_gt.shape)\n",
    "print(z1_cpp.shape)\n",
    "torch.testing.assert_close(z1_gt, z1_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3401a596-e86f-402b-97f8-1f3a27275e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8493, 0.8507],\n",
      "        [1.8493, 0.8507],\n",
      "        [1.8493, 0.8507]], device='cuda:0') tensor([-2., -2., -2.], device='cuda:0')\n",
      "tensor([[0.9247, 0.4253],\n",
      "        [0.9247, 0.4253],\n",
      "        [0.9247, 0.4253]], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Check LinearCPP backward method\n",
    "abs(z1_gt.sum()).backward(retain_graph=True)\n",
    "print(W1.grad, b1.grad)\n",
    "\n",
    "abs(z1_cpp.sum()).backward(retain_graph=True)\n",
    "print(W1_cpp.grad, b1_cpp.grad)\n",
    "\n",
    "# torch.testing.assert_close(W1.grad, -W1_cpp.grad)\n",
    "# torch.testing.assert_close(b1.grad, -b1_cpp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba54921-77c3-423a-95d3-2490a77a7d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "tensor([[-1.4722,  0.5293,  0.8059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) \n",
      " tensor([[-1.4722,  0.5293,  0.8059]], device='cuda:0',\n",
      "       grad_fn=<LinearCudaBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Check LinearCuda forward method\n",
    "W1_cuda, b1_cuda = W1.detach().clone(), b1.detach().clone()\n",
    "W1_cuda.requires_grad = True\n",
    "b1_cuda.requires_grad = True\n",
    "lin_cuda = myext.LinearCuda()\n",
    "z1_cuda = lin_cuda.apply(X, W1_cuda, b1_cuda)\n",
    "print(z1_gt.shape)\n",
    "print(z1_cuda.shape)\n",
    "print(z1_gt, \"\\n\", z1_cuda)\n",
    "torch.testing.assert_close(z1_gt, z1_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d63eab-a361-4dd1-8bb9-e936b96ca10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7740, 1.2760],\n",
      "        [2.7740, 1.2760],\n",
      "        [2.7740, 1.2760]], device='cuda:0') tensor([-3., -3., -3.], device='cuda:0')\n",
      "tensor([[0.9247, 0.4253],\n",
      "        [0.9247, 0.4253],\n",
      "        [0.9247, 0.4253]], device='cuda:0') tensor([-1., -1., -1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Check LinearCuda backward method\n",
    "abs(z1_gt.sum()).backward(retain_graph=True)\n",
    "print(W1.grad, b1.grad)\n",
    "\n",
    "abs(z1_cuda.sum()).backward(retain_graph=True)\n",
    "print(W1_cuda.grad, b1_cuda.grad)\n",
    "\n",
    "# torch.testing.assert_close(W1.grad, -W1_cuda.grad)\n",
    "# torch.testing.assert_close(b1.grad, -b1_cuda.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a88a6-ef95-49cb-9441-3c42b050b65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd9f38e1-9caf-4625-8803-bcff9fa6739f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_forward = lin_gt.forward\n",
    "# parameters = list(lin_gt.parameters())\n",
    "\n",
    "# model_forward = lin_py.apply\n",
    "# parameters = (W1_py, b1_py)\n",
    "\n",
    "# model_forward = lin_cpp.apply\n",
    "# parameters = (W1_cpp, b1_cpp)\n",
    "\n",
    "model_forward = lin_cuda.apply\n",
    "parameters = (W1_cuda, b1_cuda)\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c96d0d-231a-4cf9-a8c9-4f7eb9f1dd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1369236707687378\n",
      "[tensor([[ 0.6660,  0.4106],\n",
      "        [-0.0456, -0.2413],\n",
      "        [-0.2359, -0.1730]]), tensor([-0.6776,  0.3886,  0.5183])]\n"
     ]
    }
   ],
   "source": [
    "## Single optimizer step\n",
    "z1 = model_forward(X, *parameters)\n",
    "loss = abs(z1.sum())\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "print(loss.item())\n",
    "print([p_.detach().cpu() for p_ in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c87a7c-b801-440c-a047-fe930f169440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Optimization loop\n",
    "num_steps = 1000\n",
    "losses = []\n",
    "for _ in range(num_steps):\n",
    "    z1 = model_forward(X, *parameters)\n",
    "    loss = abs(z1.sum())\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abf2df-3733-427d-8723-f5b7efd8977d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c62d38-d16d-49e8-b1a8-b72f15ce7c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Checking backward implementation shapes\n",
    "zc = (W1 @ X.T + b1[..., None]).T\n",
    "print(W1.shape, b1.shape, zc.shape)\n",
    "\n",
    "d_z = zc\n",
    "d_X = (W1.T @ d_z.T).T\n",
    "print(d_X.shape, (n_batch, n_in))\n",
    "d_W = 1 / n_batch * (d_z.T @ X)\n",
    "print(d_W.shape, (n_h, n_in))\n",
    "d_b = 1 / n_batch * d_z.sum(dim=0, keepdims=True)\n",
    "print(d_b.shape, (n_batch, n_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bfe64-baa4-44d3-97ab-7391dda6f744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7f6ab-c1c3-4624-ac69-627c93728d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:multi] *",
   "language": "python",
   "name": "conda-env-multi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
